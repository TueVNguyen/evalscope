api_key: EMPTY
api_url: http://0.0.0.0:2596/v1
chat_template: null
dataset_args:
  aime24:
    dataset_hub: modelscope
    dataset_id: HuggingFaceH4/aime_2024
    eval_split: train
    extra_params: {}
    few_shot_num: 0
    few_shot_random: false
    filters: null
    metric_list:
    - AveragePass@1
    - TopK
    model_adapter: generation
    name: aime24
    output_types:
    - generation
    pretty_name: AIME-2024
    prompt_template: '{query}

      Please reason step by step, and put your final answer within \boxed{{}}.'
    query_template: null
    subset_list:
    - default
    system_prompt: null
    train_split: null
  aime25_full:
    few_shot_num: 0
dataset_dir: /home/pvduy/.cache/modelscope/hub/datasets
dataset_hub: modelscope
datasets:
- aime24
debug: false
dry_run: false
eval_backend: Native
eval_batch_size: 64
eval_config: null
eval_type: service
generation_config:
  max_tokens: 16384
  n: 3
  temperature: 0.6
  top_p: 0.95
judge_model_args: {}
judge_strategy: auto
judge_worker_num: 8
limit: null
mem_cache: false
model: gemini_flash_2.0
model_args:
  precision: torch.float16
  revision: master
model_id: gemini_flash_2.0
outputs: null
seed: 42
stage: all
stream: false
template_type: null
timeout: null
use_cache: null
work_dir: outputs2/20250319_192613/0
